# -*- coding: utf-8 -*-
"""Aprovacao_de_Credito.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VHSf7f8XfDMI5xoZGw1f8PMFOhalALM7
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("rikdifos/credit-card-approval-prediction")

print("Path to dataset files:", path)

import os
import pandas as pd

# Caminho do diretório
path = "/root/.cache/kagglehub/datasets/rikdifos/credit-card-approval-prediction/versions/3"

# Listar os arquivos disponíveis
os.listdir(path)

# Carregar o dataset principal
app_df = pd.read_csv(f"{path}/application_record.csv")

# Visualizar as primeiras linhas
app_df.head()
app_df.info()
app_df.isnull().sum().head(10)

credit_df = pd.read_csv(f"{path}/credit_record.csv")

credit_df.info()
credit_df.head()

# Criar variável-alvo: 1 = cliente com atraso (mau pagador), 0 = bom pagador
credit_status = credit_df.groupby('ID')['STATUS'].apply(
    lambda x: 1 if any(s in ['2', '3', '4', '5'] for s in x) else 0
).reset_index()

credit_status.rename(columns={'STATUS': 'TARGET'}, inplace=True)

credit_status['TARGET'].value_counts(normalize=True)

# Mesclar as bases pelo ID
df_merged = pd.merge(app_df, credit_status, on='ID', how='inner')

print("Shape após merge:", df_merged.shape)
df_merged['TARGET'].value_counts(normalize=True)
df_merged.head()

# Contar os valores nulos novamente na base mesclada
print("Contagem de nulos na base mesclada:")
print(df_merged.isnull().sum())

# A coluna 'OCCUPATION_TYPE' é a que tem mais nulos (cerca de 30% na base original)
# Vamos preencher os NaNs com 'Unknown' ou 'Others' para manter a informação
df_merged['OCCUPATION_TYPE'].fillna('Others', inplace=True)

# Outras colunas como 'AMT_REQ_CREDIT_BUREAU_...' também podem ter nulos.
# Como são contagens, podemos preencher com 0 (assumindo que não houve requisições)
cols_to_fill_zero = [col for col in df_merged.columns if col.startswith('AMT_REQ_CREDIT_BUREAU_')]
for col in cols_to_fill_zero:
    df_merged[col].fillna(0, inplace=True)

print("\nVerificação de nulos após o tratamento:")
print(df_merged.isnull().sum().max()) # Deve ser 0 se todas foram tratadas

# Selecionar variáveis categóricas (object type)
categorical_cols = df_merged.select_dtypes(include=['object']).columns.tolist()

print("Variáveis categóricas a serem codificadas:", categorical_cols)

# Variáveis Binárias: Converter Y/N para 1/0 (ou outras binárias)
df_merged['FLAG_OWN_CAR'] = df_merged['FLAG_OWN_CAR'].map({'Y': 1, 'N': 0})
df_merged['FLAG_OWN_REALTY'] = df_merged['FLAG_OWN_REALTY'].map({'Y': 1, 'N': 0})

# Variáveis Nominais (One-Hot Encoding)
# Usaremos pandas.get_dummies para transformar as categóricas restantes
# Excluímos 'FLAG_OWN_CAR' e 'FLAG_OWN_REALTY' pois já foram tratadas
cols_for_ohe = [col for col in categorical_cols if col not in ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY']]

df_merged_encoded = pd.get_dummies(df_merged, columns=cols_for_ohe, drop_first=True)

print("\nShape após One-Hot Encoding:", df_merged_encoded.shape)
df_merged_encoded.head()

# Criar a idade do cliente em anos (DAYS_BIRTH é negativo)
df_merged_encoded['AGE_YEARS'] = (-df_merged_encoded['DAYS_BIRTH'] // 365.25).astype(int)

# Criar anos de emprego (DAYS_EMPLOYED é negativo)
# Onde for positivo (clientes não empregados), vamos setar como 0 para indicar desemprego
df_merged_encoded['YEARS_EMPLOYED'] = df_merged_encoded['DAYS_EMPLOYED'].apply(
    lambda x: -x // 365.25 if x < 0 else 0
).astype(int)

# Razão de Renda por Membro da Família
df_merged_encoded['INCOME_PER_FAMILY_MEMBER'] = (
    df_merged_encoded['AMT_INCOME_TOTAL'] / df_merged_encoded['CNT_FAM_MEMBERS']
)

# Remover as colunas originais de tempo (DAYS_...) e o ID
df_merged_encoded.drop(columns=['ID', 'DAYS_BIRTH', 'DAYS_EMPLOYED'], inplace=True)

df_merged_encoded[['AGE_YEARS', 'YEARS_EMPLOYED', 'INCOME_PER_FAMILY_MEMBER']].head()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
from sklearn.preprocessing import StandardScaler

# Separar Features (X) e Target (y)
X = df_merged_encoded.drop('TARGET', axis=1)
y = df_merged_encoded['TARGET']

# Split em treino e teste (mantendo a proporção da target)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# Como a escala das variáveis é diferente (renda vs. contagens), é bom escalar
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Treinar um modelo simples: Regressão Logística
model = LogisticRegression(solver='liblinear', random_state=42)
model.fit(X_train_scaled, y_train)

# Previsões
y_pred = model.predict(X_test_scaled)
y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] # Probabilidade para a classe 1

print("Relatório de Classificação:\n", classification_report(y_test, y_pred))
print("Área sob a Curva ROC (AUC):", roc_auc_score(y_test, y_pred_proba))
print("\nMatriz de Confusão:\n", confusion_matrix(y_test, y_pred))

# A CURVA ROC é um ótimo resultado visual para o seu GitHub
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(y_test, y_pred_proba):.2f}')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Taxa de Falso Positivo')
plt.ylabel('Taxa de Verdadeiro Positivo')
plt.title('Curva ROC')
plt.legend(loc='lower right')
plt.show()